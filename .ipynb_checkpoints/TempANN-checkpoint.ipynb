{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-11 16:44:27.802963: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('PIMA.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 9)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>138</td>\n",
       "      <td>62</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.127</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>84</td>\n",
       "      <td>82</td>\n",
       "      <td>31</td>\n",
       "      <td>125</td>\n",
       "      <td>38.2</td>\n",
       "      <td>0.233</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>145</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>44.2</td>\n",
       "      <td>0.630</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>135</td>\n",
       "      <td>68</td>\n",
       "      <td>42</td>\n",
       "      <td>250</td>\n",
       "      <td>42.3</td>\n",
       "      <td>0.365</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>139</td>\n",
       "      <td>62</td>\n",
       "      <td>41</td>\n",
       "      <td>480</td>\n",
       "      <td>40.7</td>\n",
       "      <td>0.536</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>2</td>\n",
       "      <td>75</td>\n",
       "      <td>64</td>\n",
       "      <td>24</td>\n",
       "      <td>55</td>\n",
       "      <td>29.7</td>\n",
       "      <td>0.370</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>8</td>\n",
       "      <td>179</td>\n",
       "      <td>72</td>\n",
       "      <td>42</td>\n",
       "      <td>130</td>\n",
       "      <td>32.7</td>\n",
       "      <td>0.719</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>6</td>\n",
       "      <td>85</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31.2</td>\n",
       "      <td>0.382</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>0</td>\n",
       "      <td>129</td>\n",
       "      <td>110</td>\n",
       "      <td>46</td>\n",
       "      <td>130</td>\n",
       "      <td>67.1</td>\n",
       "      <td>0.319</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>2</td>\n",
       "      <td>81</td>\n",
       "      <td>72</td>\n",
       "      <td>15</td>\n",
       "      <td>76</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.547</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0               2      138             62             35        0  33.6   \n",
       "1               0       84             82             31      125  38.2   \n",
       "2               0      145              0              0        0  44.2   \n",
       "3               0      135             68             42      250  42.3   \n",
       "4               1      139             62             41      480  40.7   \n",
       "...           ...      ...            ...            ...      ...   ...   \n",
       "1995            2       75             64             24       55  29.7   \n",
       "1996            8      179             72             42      130  32.7   \n",
       "1997            6       85             78              0        0  31.2   \n",
       "1998            0      129            110             46      130  67.1   \n",
       "1999            2       81             72             15       76  30.1   \n",
       "\n",
       "      DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                        0.127   47        1  \n",
       "1                        0.233   23        0  \n",
       "2                        0.630   31        1  \n",
       "3                        0.365   24        1  \n",
       "4                        0.536   21        0  \n",
       "...                        ...  ...      ...  \n",
       "1995                     0.370   33        0  \n",
       "1996                     0.719   36        1  \n",
       "1997                     0.382   42        0  \n",
       "1998                     0.319   26        1  \n",
       "1999                     0.547   25        0  \n",
       "\n",
       "[2000 rows x 9 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.703500</td>\n",
       "      <td>121.182500</td>\n",
       "      <td>69.145500</td>\n",
       "      <td>20.935000</td>\n",
       "      <td>80.254000</td>\n",
       "      <td>32.193000</td>\n",
       "      <td>0.470930</td>\n",
       "      <td>33.090500</td>\n",
       "      <td>0.342000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.306063</td>\n",
       "      <td>32.068636</td>\n",
       "      <td>19.188315</td>\n",
       "      <td>16.103243</td>\n",
       "      <td>111.180534</td>\n",
       "      <td>8.149901</td>\n",
       "      <td>0.323553</td>\n",
       "      <td>11.786423</td>\n",
       "      <td>0.474498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.078000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>63.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.375000</td>\n",
       "      <td>0.244000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>32.300000</td>\n",
       "      <td>0.376000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>36.800000</td>\n",
       "      <td>0.624000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>199.000000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>744.000000</td>\n",
       "      <td>80.600000</td>\n",
       "      <td>2.420000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Pregnancies      Glucose  BloodPressure  SkinThickness      Insulin  \\\n",
       "count  2000.000000  2000.000000    2000.000000    2000.000000  2000.000000   \n",
       "mean      3.703500   121.182500      69.145500      20.935000    80.254000   \n",
       "std       3.306063    32.068636      19.188315      16.103243   111.180534   \n",
       "min       0.000000     0.000000       0.000000       0.000000     0.000000   \n",
       "25%       1.000000    99.000000      63.500000       0.000000     0.000000   \n",
       "50%       3.000000   117.000000      72.000000      23.000000    40.000000   \n",
       "75%       6.000000   141.000000      80.000000      32.000000   130.000000   \n",
       "max      17.000000   199.000000     122.000000     110.000000   744.000000   \n",
       "\n",
       "               BMI  DiabetesPedigreeFunction          Age      Outcome  \n",
       "count  2000.000000               2000.000000  2000.000000  2000.000000  \n",
       "mean     32.193000                  0.470930    33.090500     0.342000  \n",
       "std       8.149901                  0.323553    11.786423     0.474498  \n",
       "min       0.000000                  0.078000    21.000000     0.000000  \n",
       "25%      27.375000                  0.244000    24.000000     0.000000  \n",
       "50%      32.300000                  0.376000    29.000000     0.000000  \n",
       "75%      36.800000                  0.624000    40.000000     1.000000  \n",
       "max      80.600000                  2.420000    81.000000     1.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pregnancies                   int64\n",
       "Glucose                       int64\n",
       "BloodPressure                 int64\n",
       "SkinThickness                 int64\n",
       "Insulin                       int64\n",
       "BMI                         float64\n",
       "DiabetesPedigreeFunction    float64\n",
       "Age                           int64\n",
       "Outcome                       int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['DiabetesPedigreeFunction'], axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>138</td>\n",
       "      <td>62</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>84</td>\n",
       "      <td>82</td>\n",
       "      <td>31</td>\n",
       "      <td>125</td>\n",
       "      <td>38.2</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>145</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>44.2</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>135</td>\n",
       "      <td>68</td>\n",
       "      <td>42</td>\n",
       "      <td>250</td>\n",
       "      <td>42.3</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>139</td>\n",
       "      <td>62</td>\n",
       "      <td>41</td>\n",
       "      <td>480</td>\n",
       "      <td>40.7</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>2</td>\n",
       "      <td>75</td>\n",
       "      <td>64</td>\n",
       "      <td>24</td>\n",
       "      <td>55</td>\n",
       "      <td>29.7</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>8</td>\n",
       "      <td>179</td>\n",
       "      <td>72</td>\n",
       "      <td>42</td>\n",
       "      <td>130</td>\n",
       "      <td>32.7</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>6</td>\n",
       "      <td>85</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31.2</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>0</td>\n",
       "      <td>129</td>\n",
       "      <td>110</td>\n",
       "      <td>46</td>\n",
       "      <td>130</td>\n",
       "      <td>67.1</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>2</td>\n",
       "      <td>81</td>\n",
       "      <td>72</td>\n",
       "      <td>15</td>\n",
       "      <td>76</td>\n",
       "      <td>30.1</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  Age  \\\n",
       "0               2      138             62             35        0  33.6   47   \n",
       "1               0       84             82             31      125  38.2   23   \n",
       "2               0      145              0              0        0  44.2   31   \n",
       "3               0      135             68             42      250  42.3   24   \n",
       "4               1      139             62             41      480  40.7   21   \n",
       "...           ...      ...            ...            ...      ...   ...  ...   \n",
       "1995            2       75             64             24       55  29.7   33   \n",
       "1996            8      179             72             42      130  32.7   36   \n",
       "1997            6       85             78              0        0  31.2   42   \n",
       "1998            0      129            110             46      130  67.1   26   \n",
       "1999            2       81             72             15       76  30.1   25   \n",
       "\n",
       "      Outcome  \n",
       "0           1  \n",
       "1           0  \n",
       "2           1  \n",
       "3           1  \n",
       "4           0  \n",
       "...       ...  \n",
       "1995        0  \n",
       "1996        1  \n",
       "1997        0  \n",
       "1998        1  \n",
       "1999        0  \n",
       "\n",
       "[2000 rows x 8 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2000 entries, 0 to 1999\n",
      "Data columns (total 8 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   Pregnancies    2000 non-null   int64  \n",
      " 1   Glucose        2000 non-null   int64  \n",
      " 2   BloodPressure  2000 non-null   int64  \n",
      " 3   SkinThickness  2000 non-null   int64  \n",
      " 4   Insulin        2000 non-null   int64  \n",
      " 5   BMI            2000 non-null   float64\n",
      " 6   Age            2000 non-null   int64  \n",
      " 7   Outcome        2000 non-null   int64  \n",
      "dtypes: float64(1), int64(7)\n",
      "memory usage: 125.1 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pregnancies      0\n",
       "Glucose          0\n",
       "BloodPressure    0\n",
       "SkinThickness    0\n",
       "Insulin          0\n",
       "BMI              0\n",
       "Age              0\n",
       "Outcome          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(14,14))\n",
    "# sns.boxplot(data=df)\n",
    "# plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(13,13))\n",
    "# for colName in df.columns:\n",
    "#     plt.figure()\n",
    "#     sns.scatterplot(data=df[colName])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_65888/684818280.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['BloodPressure'].loc[(df['BloodPressure'] <= 30)] = np.nan\n",
      "/tmp/ipykernel_65888/684818280.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Glucose'].loc[(df['Glucose'] <= 45)] = np.nan\n"
     ]
    }
   ],
   "source": [
    "df['BloodPressure'].loc[(df['BloodPressure'] <= 30)] = np.nan\n",
    "df['Glucose'].loc[(df['Glucose'] <= 45)] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pregnancies       0\n",
       "Glucose          15\n",
       "BloodPressure    95\n",
       "SkinThickness     0\n",
       "Insulin           0\n",
       "BMI               0\n",
       "Age               0\n",
       "Outcome           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0475"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['BloodPressure'].isnull().sum()/len(df['BloodPressure'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pregnancies      0\n",
       "Glucose          0\n",
       "BloodPressure    0\n",
       "SkinThickness    0\n",
       "Insulin          0\n",
       "BMI              0\n",
       "Age              0\n",
       "Outcome          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:,:-1]\n",
    "y = df.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1890"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.to_numpy()\n",
    "y = y.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  2. , 138. ,  62. , ...,   0. ,  33.6,  47. ],\n",
       "       [  0. ,  84. ,  82. , ..., 125. ,  38.2,  23. ],\n",
       "       [  0. , 135. ,  68. , ..., 250. ,  42.3,  24. ],\n",
       "       ...,\n",
       "       [  6. ,  85. ,  78. , ...,   0. ,  31.2,  42. ],\n",
       "       [  0. , 129. , 110. , ..., 130. ,  67.1,  26. ],\n",
       "       [  2. ,  81. ,  72. , ...,  76. ,  30.1,  25. ]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, ..., 0, 1, 0])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size = 0.20, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_val, X_test, y_val, y_test = train_test_split(X_train, y_train, test_size = 0.5, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc1 = StandardScaler()\n",
    "sc1.fit(X_train)\n",
    "X_test = sc1.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('scalers/standardScaler.pkl','wb') as f:\n",
    "    pickle.dump(sc,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ann = tf.keras.models.Sequential()\n",
    "\n",
    "# ann.add(tf.keras.layers.Dense(units=7, activation='relu'))\n",
    "# ann.add(tf.keras.layers.Dense(units=14, activation='relu'))\n",
    "# ann.add(tf.keras.layers.Dense(units=50, activation='relu'))\n",
    "# ann.add(tf.keras.layers.Dense(units=75, activation='relu'))\n",
    "# ann.add(tf.keras.layers.Dense(units=50, activation='relu'))\n",
    "# ann.add(tf.keras.layers.Dense(units=14, activation='relu'))\n",
    "# ann.add(tf.keras.layers.Dense(units=7, activation='relu'))\n",
    "# ann.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "# ann.compile(loss='binary_crossentropy',\n",
    "#              optimizer='adam',\n",
    "#              metrics=[\n",
    "#                  tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "#                 tf.keras.metrics.Precision(name='precision'),\n",
    "#                 tf.keras.metrics.Recall(name='recall')\n",
    "#              ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ann = tf.keras.models.Sequential()\n",
    "\n",
    "# ann.add(tf.keras.layers.Dense(units=7, activation='relu'))\n",
    "# ann.add(tf.keras.layers.Dense(units=14, activation='relu'))\n",
    "# ann.add(tf.keras.layers.Dense(units=79, activation='relu'))\n",
    "# ann.add(tf.keras.layers.Dense(units=57, activation='relu'))\n",
    "# ann.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "# ann.compile(loss='binary_crossentropy',\n",
    "#              optimizer='adam',\n",
    "#              metrics=[\n",
    "#                 tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "#                 tf.keras.metrics.Precision(name='precision'),\n",
    "#                 tf.keras.metrics.Recall(name='recall')\n",
    "#              ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ann = tf.keras.models.Sequential()\n",
    "\n",
    "# # ann.add(tf.keras.layers.Dense(units=7, activation='relu'))\n",
    "# ann.add(tf.keras.layers.Dense(units=14, activation='relu'))\n",
    "# ann.add(tf.keras.layers.Dense(units=101, activation='relu'))\n",
    "# ann.add(tf.keras.layers.Dense(units=200, activation='relu'))\n",
    "# ann.add(tf.keras.layers.Dense(units=89, activation='relu'))\n",
    "# ann.add(tf.keras.layers.Dense(units=37, activation='relu'))\n",
    "# ann.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "# ann.compile(loss='binary_crossentropy',\n",
    "#              optimizer='adam',\n",
    "#              metrics=[\n",
    "#                 tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "#                 tf.keras.metrics.Precision(name='precision'),\n",
    "#                 tf.keras.metrics.Recall(name='recall')\n",
    "#              ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ann = tf.keras.models.Sequential()\n",
    "\n",
    "# ann.add(tf.keras.layers.Dense(units=7, activation='relu'))\n",
    "# ann.add(tf.keras.layers.Dense(units=131, activation='relu'))\n",
    "# ann.add(tf.keras.layers.Dense(units=274, activation='relu'))\n",
    "# ann.add(tf.keras.layers.Dense(units=479, activation='relu'))\n",
    "# ann.add(tf.keras.layers.Dense(units=389, activation='relu'))\n",
    "# ann.add(tf.keras.layers.Dense(units=59, activation='relu'))\n",
    "# ann.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "# ann.compile(loss='binary_crossentropy',\n",
    "#              optimizer='adam',\n",
    "#              metrics=[\n",
    "#                 tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "#                 tf.keras.metrics.Precision(name='precision'),\n",
    "#                 tf.keras.metrics.Recall(name='recall')\n",
    "#              ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-11 16:44:29.551088: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-04-11 16:44:29.551530: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-04-11 16:44:29.551549: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-04-11 16:44:29.551574: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (RSPL-346): /proc/driver/nvidia/version does not exist\n",
      "2022-04-11 16:44:29.551849: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-04-11 16:44:29.552491: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n"
     ]
    }
   ],
   "source": [
    "ann = tf.keras.models.Sequential()\n",
    "\n",
    "ann.add(tf.keras.layers.Dense(units=7, activation='relu'))\n",
    "ann.add(tf.keras.layers.Dense(units=132, activation='relu'))\n",
    "ann.add(tf.keras.layers.Dense(units=279, activation='relu'))\n",
    "ann.add(tf.keras.layers.Dense(units=423, activation='relu'))\n",
    "ann.add(tf.keras.layers.Dense(units=579, activation='relu'))\n",
    "ann.add(tf.keras.layers.Dense(units=456, activation='relu'))\n",
    "ann.add(tf.keras.layers.Dense(units=303, activation='relu'))\n",
    "ann.add(tf.keras.layers.Dense(units=154, activation='relu'))\n",
    "ann.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "ann.compile(loss='binary_crossentropy',\n",
    "             optimizer='adam',\n",
    "             metrics=[\n",
    "                tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "                tf.keras.metrics.Precision(name='precision'),\n",
    "                tf.keras.metrics.Recall(name='recall')\n",
    "             ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import cross_val_score\n",
    "# accuracies = cross_val_score(estimator=ann, X=X_train, y=y_train, cv= 10)\n",
    "# print(f'Accuracies: {accuracies}')\n",
    "# print('Mean Accuracy: {:.2f}'.format(accuracies.mean()))\n",
    "# print('Standard Deviation of Accuracies: {:.2f}'.format(accuracies.std()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-11 16:44:29.675653: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2022-04-11 16:44:29.698408: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 1999965000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "43/43 [==============================] - 1s 7ms/step - loss: 0.5777 - accuracy: 0.6667 - precision: 0.4300 - recall: 0.2837\n",
      "Epoch 2/20\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.5031 - accuracy: 0.7393 - precision: 0.6051 - recall: 0.6368\n",
      "Epoch 3/20\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.4728 - accuracy: 0.7498 - precision: 0.6128 - recall: 0.5570\n",
      "Epoch 4/20\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.4611 - accuracy: 0.7702 - precision: 0.6606 - recall: 0.5649\n",
      "Epoch 5/20\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.4735 - accuracy: 0.7624 - precision: 0.6581 - recall: 0.5859\n",
      "Epoch 6/20\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.4691 - accuracy: 0.7627 - precision: 0.6660 - recall: 0.6271\n",
      "Epoch 7/20\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.4288 - accuracy: 0.7938 - precision: 0.6864 - recall: 0.7223\n",
      "Epoch 8/20\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.4304 - accuracy: 0.7965 - precision: 0.7188 - recall: 0.7087\n",
      "Epoch 9/20\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.4172 - accuracy: 0.8002 - precision: 0.6967 - recall: 0.6888\n",
      "Epoch 10/20\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.3978 - accuracy: 0.8157 - precision: 0.7289 - recall: 0.7163\n",
      "Epoch 11/20\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.3581 - accuracy: 0.8285 - precision: 0.7740 - recall: 0.6895\n",
      "Epoch 12/20\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.3568 - accuracy: 0.8184 - precision: 0.7412 - recall: 0.7202\n",
      "Epoch 13/20\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.3098 - accuracy: 0.8576 - precision: 0.8311 - recall: 0.7178\n",
      "Epoch 14/20\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.3018 - accuracy: 0.8583 - precision: 0.8233 - recall: 0.7305\n",
      "Epoch 15/20\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.3177 - accuracy: 0.8422 - precision: 0.7548 - recall: 0.7847\n",
      "Epoch 16/20\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.2963 - accuracy: 0.8545 - precision: 0.7480 - recall: 0.8289\n",
      "Epoch 17/20\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.2611 - accuracy: 0.8722 - precision: 0.8092 - recall: 0.7883\n",
      "Epoch 18/20\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.2611 - accuracy: 0.8832 - precision: 0.8263 - recall: 0.8103\n",
      "Epoch 19/20\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.2907 - accuracy: 0.8545 - precision: 0.8172 - recall: 0.7521\n",
      "Epoch 20/20\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.2533 - accuracy: 0.8818 - precision: 0.8497 - recall: 0.7992\n",
      "0.7960526315789473\n",
      "0.7142857142857143\n",
      "0.6451612903225806\n",
      "0.5633802816901409\n",
      "Epoch 1/20\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.2861 - accuracy: 0.8801 - precision: 0.8462 - recall: 0.7715\n",
      "Epoch 2/20\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.2452 - accuracy: 0.9007 - precision: 0.8404 - recall: 0.8575\n",
      "Epoch 3/20\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.2484 - accuracy: 0.9081 - precision: 0.8838 - recall: 0.8258\n",
      "Epoch 4/20\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.2041 - accuracy: 0.9154 - precision: 0.8724 - recall: 0.8665\n",
      "Epoch 5/20\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.2320 - accuracy: 0.8993 - precision: 0.8571 - recall: 0.8281\n",
      "Epoch 6/20\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.2008 - accuracy: 0.9191 - precision: 0.8756 - recall: 0.8756\n",
      "Epoch 7/20\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.1847 - accuracy: 0.9191 - precision: 0.8843 - recall: 0.8643\n",
      "Epoch 8/20\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.1843 - accuracy: 0.9169 - precision: 0.8817 - recall: 0.8597\n",
      "Epoch 9/20\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.1735 - accuracy: 0.9316 - precision: 0.8993 - recall: 0.8891\n",
      "Epoch 10/20\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.1802 - accuracy: 0.9316 - precision: 0.9049 - recall: 0.8824\n",
      "Epoch 11/20\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.1685 - accuracy: 0.9324 - precision: 0.9089 - recall: 0.8801\n",
      "Epoch 12/20\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.1480 - accuracy: 0.9412 - precision: 0.9249 - recall: 0.8914\n",
      "Epoch 13/20\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.1369 - accuracy: 0.9412 - precision: 0.9151 - recall: 0.9027\n",
      "Epoch 14/20\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.1588 - accuracy: 0.9338 - precision: 0.9018 - recall: 0.8937\n",
      "Epoch 15/20\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.1434 - accuracy: 0.9390 - precision: 0.9367 - recall: 0.8710\n",
      "Epoch 16/20\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.1436 - accuracy: 0.9426 - precision: 0.9483 - recall: 0.8710\n",
      "Epoch 17/20\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.1639 - accuracy: 0.9324 - precision: 0.8959 - recall: 0.8959\n",
      "Epoch 18/20\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.1304 - accuracy: 0.9456 - precision: 0.9126 - recall: 0.9208\n",
      "Epoch 19/20\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.1088 - accuracy: 0.9596 - precision: 0.9469 - recall: 0.9276\n",
      "Epoch 20/20\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.1359 - accuracy: 0.9353 - precision: 0.9060 - recall: 0.8937\n",
      "0.8552631578947368\n",
      "0.9019607843137255\n",
      "0.8614232209737828\n",
      "0.8070175438596492\n",
      "Epoch 1/20\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.1268 - accuracy: 0.9493 - precision: 0.9369 - recall: 0.9103\n",
      "Epoch 2/20\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.1324 - accuracy: 0.9449 - precision: 0.9442 - recall: 0.8884\n",
      "Epoch 3/20\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.1571 - accuracy: 0.9383 - precision: 0.9307 - recall: 0.8818\n",
      "Epoch 4/20\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.1122 - accuracy: 0.9537 - precision: 0.9339 - recall: 0.9278\n",
      "Epoch 5/20\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0915 - accuracy: 0.9662 - precision: 0.9660 - recall: 0.9322\n",
      "Epoch 6/20\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0868 - accuracy: 0.9677 - precision: 0.9683 - recall: 0.9344\n",
      "Epoch 7/20\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.0918 - accuracy: 0.9640 - precision: 0.9554 - recall: 0.9365\n",
      "Epoch 8/20\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0942 - accuracy: 0.9566 - precision: 0.9442 - recall: 0.9256\n",
      "Epoch 9/20\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.1619 - accuracy: 0.9383 - precision: 0.9046 - recall: 0.9125\n",
      "Epoch 10/20\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.1586 - accuracy: 0.9456 - precision: 0.9570 - recall: 0.8775\n",
      "Epoch 11/20\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.1346 - accuracy: 0.9486 - precision: 0.9290 - recall: 0.9168\n",
      "Epoch 12/20\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.1116 - accuracy: 0.9530 - precision: 0.9497 - recall: 0.9081\n",
      "Epoch 13/20\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.1360 - accuracy: 0.9552 - precision: 0.9459 - recall: 0.9190\n",
      "Epoch 14/20\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.1006 - accuracy: 0.9640 - precision: 0.9595 - recall: 0.9322\n",
      "Epoch 15/20\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.1013 - accuracy: 0.9677 - precision: 0.9579 - recall: 0.9453\n",
      "Epoch 16/20\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0623 - accuracy: 0.9772 - precision: 0.9797 - recall: 0.9519\n",
      "Epoch 17/20\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.1352 - accuracy: 0.9537 - precision: 0.9477 - recall: 0.9125\n",
      "Epoch 18/20\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.1191 - accuracy: 0.9493 - precision: 0.9619 - recall: 0.8840\n",
      "Epoch 19/20\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0829 - accuracy: 0.9699 - precision: 0.9706 - recall: 0.9387\n",
      "Epoch 20/20\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0959 - accuracy: 0.9677 - precision: 0.9599 - recall: 0.9431\n",
      "0.9668874172185431\n",
      "0.9777777777777777\n",
      "0.9649122807017544\n",
      "0.946236559139785\n",
      "Epoch 1/20\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0895 - accuracy: 0.9647 - precision: 0.9564 - recall: 0.9400\n",
      "Epoch 2/20\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.0760 - accuracy: 0.9721 - precision: 0.9593 - recall: 0.9593\n",
      "Epoch 3/20\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.0702 - accuracy: 0.9743 - precision: 0.9675 - recall: 0.9572\n",
      "Epoch 4/20\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.0871 - accuracy: 0.9750 - precision: 0.9636 - recall: 0.9636\n",
      "Epoch 5/20\n",
      "43/43 [==============================] - 0s 10ms/step - loss: 0.1032 - accuracy: 0.9574 - precision: 0.9234 - recall: 0.9550\n",
      "Epoch 6/20\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0752 - accuracy: 0.9684 - precision: 0.9629 - recall: 0.9443\n",
      "Epoch 7/20\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.1266 - accuracy: 0.9574 - precision: 0.9323 - recall: 0.9443\n",
      "Epoch 8/20\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0650 - accuracy: 0.9750 - precision: 0.9717 - recall: 0.9550\n",
      "Epoch 9/20\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0613 - accuracy: 0.9728 - precision: 0.9694 - recall: 0.9507\n",
      "Epoch 10/20\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0528 - accuracy: 0.9780 - precision: 0.9760 - recall: 0.9593\n",
      "Epoch 11/20\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0570 - accuracy: 0.9780 - precision: 0.9740 - recall: 0.9615\n",
      "Epoch 12/20\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0439 - accuracy: 0.9802 - precision: 0.9762 - recall: 0.9657\n",
      "Epoch 13/20\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0431 - accuracy: 0.9831 - precision: 0.9890 - recall: 0.9615\n",
      "Epoch 14/20\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0660 - accuracy: 0.9787 - precision: 0.9740 - recall: 0.9636\n",
      "Epoch 15/20\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0453 - accuracy: 0.9802 - precision: 0.9846 - recall: 0.9572\n",
      "Epoch 16/20\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0621 - accuracy: 0.9765 - precision: 0.9718 - recall: 0.9593\n",
      "Epoch 17/20\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0839 - accuracy: 0.9699 - precision: 0.9712 - recall: 0.9400\n",
      "Epoch 18/20\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.1654 - accuracy: 0.9383 - precision: 0.8998 - recall: 0.9229\n",
      "Epoch 19/20\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.1063 - accuracy: 0.9596 - precision: 0.9459 - recall: 0.9358\n",
      "Epoch 20/20\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0682 - accuracy: 0.9758 - precision: 0.9677 - recall: 0.9615\n",
      "0.9933774834437086\n",
      "0.9743589743589743\n",
      "0.9793814432989689\n",
      "0.9870129870129869\n",
      "Epoch 1/20\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0561 - accuracy: 0.9838 - precision: 0.9774 - recall: 0.9730\n",
      "Epoch 2/20\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0873 - accuracy: 0.9713 - precision: 0.9765 - recall: 0.9347\n",
      "Epoch 3/20\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0611 - accuracy: 0.9765 - precision: 0.9725 - recall: 0.9550\n",
      "Epoch 4/20\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0440 - accuracy: 0.9816 - precision: 0.9794 - recall: 0.9640\n",
      "Epoch 5/20\n",
      "43/43 [==============================] - 0s 10ms/step - loss: 0.0353 - accuracy: 0.9846 - precision: 0.9818 - recall: 0.9707\n",
      "Epoch 6/20\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.0323 - accuracy: 0.9846 - precision: 0.9753 - recall: 0.9775\n",
      "Epoch 7/20\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0431 - accuracy: 0.9853 - precision: 0.9930 - recall: 0.9617\n",
      "Epoch 8/20\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0828 - accuracy: 0.9787 - precision: 0.9770 - recall: 0.9572\n",
      "Epoch 9/20\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0518 - accuracy: 0.9831 - precision: 0.9817 - recall: 0.9662\n",
      "Epoch 10/20\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0278 - accuracy: 0.9897 - precision: 0.9864 - recall: 0.9820\n",
      "Epoch 11/20\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0704 - accuracy: 0.9787 - precision: 0.9770 - recall: 0.9572\n",
      "Epoch 12/20\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0352 - accuracy: 0.9853 - precision: 0.9840 - recall: 0.9707\n",
      "Epoch 13/20\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0573 - accuracy: 0.9824 - precision: 0.9751 - recall: 0.9707\n",
      "Epoch 14/20\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.1293 - accuracy: 0.9544 - precision: 0.9302 - recall: 0.9302\n",
      "Epoch 15/20\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0820 - accuracy: 0.9713 - precision: 0.9551 - recall: 0.9572\n",
      "Epoch 16/20\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0449 - accuracy: 0.9765 - precision: 0.9682 - recall: 0.9595\n",
      "Epoch 17/20\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 0.0644 - accuracy: 0.9758 - precision: 0.9681 - recall: 0.9572\n",
      "Epoch 18/20\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 0.0447 - accuracy: 0.9838 - precision: 0.9817 - recall: 0.9685\n",
      "Epoch 19/20\n",
      "43/43 [==============================] - 0s 10ms/step - loss: 0.0299 - accuracy: 0.9868 - precision: 0.9797 - recall: 0.9797\n",
      "Epoch 20/20\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 0.0301 - accuracy: 0.9882 - precision: 0.9842 - recall: 0.9797\n",
      "0.9867549668874173\n",
      "1.0\n",
      "0.9932659932659933\n",
      "0.9833333333333333\n",
      "Epoch 1/20\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0540 - accuracy: 0.9794 - precision: 0.9778 - recall: 0.9608\n",
      "Epoch 2/20\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0539 - accuracy: 0.9838 - precision: 0.9823 - recall: 0.9695\n",
      "Epoch 3/20\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0492 - accuracy: 0.9846 - precision: 0.9700 - recall: 0.9847\n",
      "Epoch 4/20\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0539 - accuracy: 0.9831 - precision: 0.9760 - recall: 0.9739\n",
      "Epoch 5/20\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.1404 - accuracy: 0.9596 - precision: 0.9612 - recall: 0.9172\n",
      "Epoch 6/20\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.1331 - accuracy: 0.9589 - precision: 0.9528 - recall: 0.9237\n",
      "Epoch 7/20\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0955 - accuracy: 0.9721 - precision: 0.9586 - recall: 0.9586\n",
      "Epoch 8/20\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0376 - accuracy: 0.9897 - precision: 0.9890 - recall: 0.9804\n",
      "Epoch 9/20\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0364 - accuracy: 0.9868 - precision: 0.9804 - recall: 0.9804\n",
      "Epoch 10/20\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0270 - accuracy: 0.9890 - precision: 0.9912 - recall: 0.9760\n",
      "Epoch 11/20\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0254 - accuracy: 0.9904 - precision: 0.9869 - recall: 0.9847\n",
      "Epoch 12/20\n",
      "43/43 [==============================] - 0s 11ms/step - loss: 0.0375 - accuracy: 0.9831 - precision: 0.9760 - recall: 0.9739\n",
      "Epoch 13/20\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0381 - accuracy: 0.9838 - precision: 0.9740 - recall: 0.9782\n",
      "Epoch 14/20\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0182 - accuracy: 0.9919 - precision: 0.9912 - recall: 0.9847\n",
      "Epoch 15/20\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0311 - accuracy: 0.9868 - precision: 0.9846 - recall: 0.9760\n",
      "Epoch 16/20\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0252 - accuracy: 0.9897 - precision: 0.9847 - recall: 0.9847\n",
      "Epoch 17/20\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0665 - accuracy: 0.9809 - precision: 0.9656 - recall: 0.9782\n",
      "Epoch 18/20\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0459 - accuracy: 0.9809 - precision: 0.9676 - recall: 0.9760\n",
      "Epoch 19/20\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0244 - accuracy: 0.9912 - precision: 0.9956 - recall: 0.9782\n",
      "Epoch 20/20\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0142 - accuracy: 0.9934 - precision: 0.9956 - recall: 0.9847\n",
      "0.9933774834437086\n",
      "1.0\n",
      "0.9955752212389382\n",
      "0.989010989010989\n",
      "Epoch 1/20\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0613 - accuracy: 0.9846 - precision: 0.9845 - recall: 0.9696\n",
      "Epoch 2/20\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.1178 - accuracy: 0.9581 - precision: 0.9390 - recall: 0.9370\n",
      "Epoch 3/20\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0461 - accuracy: 0.9750 - precision: 0.9513 - recall: 0.9761\n",
      "Epoch 4/20\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0269 - accuracy: 0.9904 - precision: 0.9848 - recall: 0.9870\n",
      "Epoch 5/20\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0209 - accuracy: 0.9912 - precision: 0.9956 - recall: 0.9783\n",
      "Epoch 6/20\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0261 - accuracy: 0.9941 - precision: 0.9934 - recall: 0.9891\n",
      "Epoch 7/20\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0362 - accuracy: 0.9875 - precision: 0.9763 - recall: 0.9870\n",
      "Epoch 8/20\n",
      "43/43 [==============================] - 0s 10ms/step - loss: 0.0254 - accuracy: 0.9904 - precision: 0.9848 - recall: 0.9870\n",
      "Epoch 9/20\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 0.0463 - accuracy: 0.9838 - precision: 0.9845 - recall: 0.9674\n",
      "Epoch 10/20\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.0228 - accuracy: 0.9904 - precision: 0.9934 - recall: 0.9783\n",
      "Epoch 11/20\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0106 - accuracy: 0.9963 - precision: 0.9978 - recall: 0.9913\n",
      "Epoch 12/20\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0140 - accuracy: 0.9941 - precision: 0.9934 - recall: 0.9891\n",
      "Epoch 13/20\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0154 - accuracy: 0.9934 - precision: 0.9892 - recall: 0.9913\n",
      "Epoch 14/20\n",
      "43/43 [==============================] - 1s 12ms/step - loss: 0.0101 - accuracy: 0.9949 - precision: 0.9956 - recall: 0.9891\n",
      "Epoch 15/20\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0071 - accuracy: 0.9963 - precision: 0.9978 - recall: 0.9913\n",
      "Epoch 16/20\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0056 - accuracy: 0.9978 - precision: 0.9978 - recall: 0.9957\n",
      "Epoch 17/20\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0048 - accuracy: 0.9978 - precision: 0.9978 - recall: 0.9957\n",
      "Epoch 18/20\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0046 - accuracy: 0.9978 - precision: 0.9978 - recall: 0.9957\n",
      "Epoch 19/20\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0045 - accuracy: 0.9971 - precision: 0.9978 - recall: 0.9935\n",
      "Epoch 20/20\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0041 - accuracy: 0.9978 - precision: 0.9978 - recall: 0.9957\n",
      "0.9933774834437086\n",
      "0.9782608695652174\n",
      "0.982532751091703\n",
      "0.989010989010989\n",
      "Epoch 1/20\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0048 - accuracy: 0.9971 - precision: 0.9977 - recall: 0.9933\n",
      "Epoch 2/20\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0042 - accuracy: 0.9978 - precision: 1.0000 - recall: 0.9933\n",
      "Epoch 3/20\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0319 - accuracy: 0.9912 - precision: 0.9822 - recall: 0.9910\n",
      "Epoch 4/20\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.1244 - accuracy: 0.9603 - precision: 0.9474 - recall: 0.9303\n",
      "Epoch 5/20\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0728 - accuracy: 0.9772 - precision: 0.9705 - recall: 0.9596\n",
      "Epoch 6/20\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0800 - accuracy: 0.9765 - precision: 0.9725 - recall: 0.9551\n",
      "Epoch 7/20\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0642 - accuracy: 0.9824 - precision: 0.9752 - recall: 0.9708\n",
      "Epoch 8/20\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0574 - accuracy: 0.9787 - precision: 0.9771 - recall: 0.9573\n",
      "Epoch 9/20\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0474 - accuracy: 0.9838 - precision: 0.9774 - recall: 0.9730\n",
      "Epoch 10/20\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0598 - accuracy: 0.9780 - precision: 0.9601 - recall: 0.9730\n",
      "Epoch 11/20\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0459 - accuracy: 0.9831 - precision: 0.9752 - recall: 0.9730\n",
      "Epoch 12/20\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0367 - accuracy: 0.9853 - precision: 0.9841 - recall: 0.9708\n",
      "Epoch 13/20\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0292 - accuracy: 0.9897 - precision: 0.9909 - recall: 0.9775\n",
      "Epoch 14/20\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0102 - accuracy: 0.9971 - precision: 0.9933 - recall: 0.9978\n",
      "Epoch 15/20\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0090 - accuracy: 0.9971 - precision: 0.9955 - recall: 0.9955\n",
      "Epoch 16/20\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0593 - accuracy: 0.9846 - precision: 0.9753 - recall: 0.9775\n",
      "Epoch 17/20\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.1136 - accuracy: 0.9640 - precision: 0.9342 - recall: 0.9573\n",
      "Epoch 18/20\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0469 - accuracy: 0.9868 - precision: 0.9798 - recall: 0.9798\n",
      "Epoch 19/20\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0375 - accuracy: 0.9860 - precision: 0.9797 - recall: 0.9775\n",
      "Epoch 20/20\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.0562 - accuracy: 0.9802 - precision: 0.9665 - recall: 0.9730\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "Epoch 1/20\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0304 - accuracy: 0.9897 - precision: 0.9866 - recall: 0.9822\n",
      "Epoch 2/20\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0870 - accuracy: 0.9758 - precision: 0.9581 - recall: 0.9688\n",
      "Epoch 3/20\n",
      "43/43 [==============================] - 0s 10ms/step - loss: 0.0292 - accuracy: 0.9904 - precision: 0.9781 - recall: 0.9933\n",
      "Epoch 4/20\n",
      "43/43 [==============================] - 0s 11ms/step - loss: 0.0274 - accuracy: 0.9897 - precision: 0.9780 - recall: 0.9911\n",
      "Epoch 5/20\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 0.0530 - accuracy: 0.9846 - precision: 0.9820 - recall: 0.9710\n",
      "Epoch 6/20\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0193 - accuracy: 0.9934 - precision: 0.9867 - recall: 0.9933\n",
      "Epoch 7/20\n",
      "43/43 [==============================] - 0s 8ms/step - loss: 0.0585 - accuracy: 0.9890 - precision: 0.9865 - recall: 0.9800\n",
      "Epoch 8/20\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0440 - accuracy: 0.9868 - precision: 0.9800 - recall: 0.9800\n",
      "Epoch 9/20\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0168 - accuracy: 0.9956 - precision: 0.9933 - recall: 0.9933\n",
      "Epoch 10/20\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0335 - accuracy: 0.9912 - precision: 0.9866 - recall: 0.9866\n",
      "Epoch 11/20\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0342 - accuracy: 0.9912 - precision: 0.9845 - recall: 0.9889\n",
      "Epoch 12/20\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0121 - accuracy: 0.9956 - precision: 1.0000 - recall: 0.9866\n",
      "Epoch 13/20\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0077 - accuracy: 0.9978 - precision: 1.0000 - recall: 0.9933\n",
      "Epoch 14/20\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0066 - accuracy: 0.9985 - precision: 1.0000 - recall: 0.9955\n",
      "Epoch 15/20\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0088 - accuracy: 0.9963 - precision: 0.9955 - recall: 0.9933\n",
      "Epoch 16/20\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0064 - accuracy: 0.9978 - precision: 0.9978 - recall: 0.9955\n",
      "Epoch 17/20\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0054 - accuracy: 0.9978 - precision: 1.0000 - recall: 0.9933\n",
      "Epoch 18/20\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0220 - accuracy: 0.9934 - precision: 0.9911 - recall: 0.9889\n",
      "Epoch 19/20\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0089 - accuracy: 0.9971 - precision: 0.9978 - recall: 0.9933\n",
      "Epoch 20/20\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0048 - accuracy: 0.9978 - precision: 0.9978 - recall: 0.9955\n",
      "0.9933774834437086\n",
      "1.0\n",
      "0.9963768115942028\n",
      "0.9909909909909909\n",
      "Epoch 1/20\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0399 - accuracy: 0.9912 - precision: 0.9891 - recall: 0.9848\n",
      "Epoch 2/20\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0311 - accuracy: 0.9882 - precision: 0.9826 - recall: 0.9826\n",
      "Epoch 3/20\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0576 - accuracy: 0.9846 - precision: 0.9700 - recall: 0.9848\n",
      "Epoch 4/20\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0746 - accuracy: 0.9787 - precision: 0.9575 - recall: 0.9804\n",
      "Epoch 5/20\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0708 - accuracy: 0.9816 - precision: 0.9698 - recall: 0.9761\n",
      "Epoch 6/20\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0325 - accuracy: 0.9890 - precision: 0.9890 - recall: 0.9783\n",
      "Epoch 7/20\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0411 - accuracy: 0.9912 - precision: 0.9912 - recall: 0.9826\n",
      "Epoch 8/20\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0072 - accuracy: 0.9963 - precision: 0.9956 - recall: 0.9935\n",
      "Epoch 9/20\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0060 - accuracy: 0.9985 - precision: 1.0000 - recall: 0.9957\n",
      "Epoch 10/20\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0034 - accuracy: 0.9985 - precision: 1.0000 - recall: 0.9957\n",
      "Epoch 11/20\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0028 - accuracy: 0.9985 - precision: 1.0000 - recall: 0.9957\n",
      "Epoch 12/20\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0444 - accuracy: 0.9904 - precision: 0.9848 - recall: 0.9870\n",
      "Epoch 13/20\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.1028 - accuracy: 0.9721 - precision: 0.9839 - recall: 0.9326\n",
      "Epoch 14/20\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0504 - accuracy: 0.9824 - precision: 0.9888 - recall: 0.9587\n",
      "Epoch 15/20\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0269 - accuracy: 0.9912 - precision: 0.9934 - recall: 0.9804\n",
      "Epoch 16/20\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 0.0306 - accuracy: 0.9904 - precision: 0.9934 - recall: 0.9783\n",
      "Epoch 17/20\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 0.0208 - accuracy: 0.9912 - precision: 0.9891 - recall: 0.9848\n",
      "Epoch 18/20\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0130 - accuracy: 0.9934 - precision: 0.9934 - recall: 0.9870\n",
      "Epoch 19/20\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.0227 - accuracy: 0.9934 - precision: 0.9913 - recall: 0.9891\n",
      "Epoch 20/20\n",
      "43/43 [==============================] - 0s 7ms/step - loss: 0.0407 - accuracy: 0.9860 - precision: 0.9868 - recall: 0.9717\n",
      "0.9933774834437086\n",
      "1.0\n",
      "0.9954751131221717\n",
      "0.9887640449438202\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score,fbeta_score, f1_score\n",
    "\n",
    "n_split=10\n",
    "\n",
    "for train_index,test_index in KFold(n_split).split(X_train):\n",
    "  x_train,x_test=X[train_index],X[test_index]\n",
    "  y_train,y_test=y[train_index],y[test_index]\n",
    "\n",
    "  sc = StandardScaler()\n",
    "  x_train = sc.fit_transform(x_train)\n",
    "  x_test = sc.transform(x_test)\n",
    "  \n",
    "  \n",
    "  ann.fit(x_train, y_train, epochs=20)\n",
    "  y_pred = ann.predict(x_test)\n",
    "  y_pred = np.array([0  if i<0.5 else 1 for i in y_pred])\n",
    "\n",
    "  # ann.evaluate(x_test, y_test)\n",
    "\n",
    "  print(accuracy_score(y_test,y_pred))\n",
    "  print(precision_score(y_test, y_pred))\n",
    "  print(fbeta_score(y_test, y_pred, beta=0.5))\n",
    "  print(f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ann.fit(X_train, y_train, batch_size=32, epochs=420)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = ann.predict(X_test)\n",
    "Y_pred = np.array([0  if i<0.5 else 1 for i in Y_pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[254,   1],\n",
       "       [  5, 118]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(Y_test, Y_pred) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9841269841269841\n",
      "0.9915966386554622\n",
      "0.9849749582637729\n",
      "0.9752066115702479\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score,fbeta_score, f1_score\n",
    "print(accuracy_score(Y_test,Y_pred))\n",
    "print(precision_score(Y_test, Y_pred))\n",
    "print(fbeta_score(Y_test, Y_pred, beta=0.5))\n",
    "print(f1_score(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.976\n",
    "\n",
    "0.945"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import accuracy_score, precision_score,fbeta_score, f1_score\n",
    "# print(accuracy_score(y_test,y_pred))\n",
    "# print(precision_score(y_test, y_pred))\n",
    "# print(fbeta_score(y_test, y_pred, beta=0.5))\n",
    "# print(f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.973\n",
    "\n",
    "0.952\n",
    "\n",
    "0.955\n",
    "\n",
    "0.959"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-11 16:45:31.266070: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/annModel/assets\n"
     ]
    }
   ],
   "source": [
    "ann.save('models/annModel')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics as metrics\n",
    "\n",
    "preds = Y_pred\n",
    "\n",
    "fpr, tpr, threshold = metrics.roc_curve(Y_test, preds)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 1 0]\n"
     ]
    }
   ],
   "source": [
    "print(threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.95934959, 1.        ])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.9775415276229054, 0.0]\n",
      "Best Threshold=1.000000, G-Mean=0.978\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "gmeans = []\n",
    "for iq in range(len(tpr)):\n",
    "   gmeans.append(math.sqrt(np.array(tpr[iq]) * (1-np.array(fpr[iq]))))\n",
    "print(gmeans)\n",
    "\n",
    "ix = np.argmax(gmeans)\n",
    "print('Best Threshold=%f, G-Mean=%.3f' % (threshold[ix], gmeans[ix]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 is the optimal threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
